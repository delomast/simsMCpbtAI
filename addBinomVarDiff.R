# running simulations to test scobi_deux and MLE
# using parallel processing to speed up simulations
# this is one variable, different between W and HNC of large scenario

#install if haven't already
# devtools::install_github("delomast/fishCompTools")

###################
## NOTE: 
##   1. this uses forking through the parallel package, so it will not work on Windows systems unless you set number of cores to 1
##   2. this is made parallel by generating multiple datasets in groups of numSims. if numSims is large and/or the sampRate * popSize
##        is large, this will use a lot of memory. Can be avoided by have repetitions of the same sampling rate in sampRate.
###################

#load libraries
library(fishCompTools, lib.loc = "../../Rlib/")
library(parallel)

# first, load in the base scenario inputs

# relative sizes of the wild groups
gsiComp <- read.table("./inputs/baseScenario/gsiCompIn.txt", header = TRUE, stringsAsFactors = FALSE, sep = "\t")

# relative sizes of the unclipped hatchery groups
pbtComp <- read.table("./inputs/baseScenario/pbtCompIn.txt", header = TRUE, stringsAsFactors = FALSE, sep = "\t")

# gsi assignmnet of the unclipped hatchery groups
gsiOfPbt <- read.table("./inputs/baseScenario/gsiOfPbtIn.txt", header = TRUE, stringsAsFactors = FALSE, sep = "\t")
# normalize
for(i in 1:nrow(gsiOfPbt)){
	gsiOfPbt[i,2:ncol(gsiOfPbt)] <- gsiOfPbt[i,2:ncol(gsiOfPbt)] / sum(gsiOfPbt[i,2:ncol(gsiOfPbt)])
}
#move group names to rownames
rownames(gsiOfPbt) <- gsiOfPbt[,1]
gsiOfPbt <- gsiOfPbt[,2:ncol(gsiOfPbt)]

# true proportion of each strata that is wild
propWild <- read.table("./inputs/baseScenario/propWildIn.txt", header = TRUE, stringsAsFactors = FALSE, sep = "\t")

# population sizes
popSize <- read.table("./inputs/baseScenario/popSizeIn.txt", header = TRUE, stringsAsFactors = FALSE, sep = "\t")

# tag rates
tagRates <- read.table("./inputs/baseScenario/tagRatesIn.txt", header = TRUE, stringsAsFactors = FALSE, sep = "\t")


# scenarios to investigate:
## sample rate
## relatively similar tag rates ?
## highly variable tag rates ?
## one sub-variable, similar between wild and hatchery - THIS SCRIPT
## one sub-variable, distinct between wild and hatchery
## GSI composition similar between PBT groups
## GSI composition distinct between PBT groups

# sample rate
sampRate <- c(.2, .2) # just one sample rate for these sims

#number of sims for each sample rate
numSims <- 500

## SD normal no bootstraps, SD tags 100%, SD spibetr=FALSE, MLE no bootstraps

## didn't keep PBT names the same as generated by the function - woops!
allGroups <- c(gsub("PBTgroup", "pbtGroup", pbtComp$Group), gsiComp$Group)
#edit for variable
allGroups <- c(paste0(allGroups, "_cat1"), paste0(allGroups, "_cat2"))

# empty data structure to save results - point estimates and CIs
#record sample rates for each iteration
srRec <- rep(0, numSims*length(sampRate))
# record true composition of variable
trueVarMat <- list()

## for SD - normal
srSD_mean <- matrix(NA, nrow = numSims*length(sampRate), ncol = length(allGroups))
colnames(srSD_mean) <- allGroups
srSD_upper <- srSD_mean
srSD_lower <- srSD_mean

#for SD tag rates 100%
srSD_tag100 <- srSD_mean

#for SD spibetr=FALSE
srSD_spibetrFALSE <- srSD_mean

## for MLE
srMLE_mean <- srSD_mean
srMLE_lower <- srSD_mean
srMLE_upper <- srSD_mean
convergeMLE <- rep(NA, nrow(srSD_mean)) ## TRUE if fail to converge, FALSE if did converge


currentRow <- 1

#parallel options
countCores <- detectCores()

#set seed for R
set.seed(7)


#####################
## defining function to calculate estimates and return estimates in a semi-convenient form

compFunc <- function(data){
	
	#unpack input
	trapData <- data[[1]]
	tags <- data[[2]]
	r <- data[[3]]
	popSize <- data[[4]]
	
	#set variables
	convergeBool <- NA
	srRec[1] <- sr #sample rate corresponding to that row

	
	###############################
	#run SD - normal
	###############################
	
	#create window count input
	window <- cbind(popSize, 1:nrow(popSize))

	#run to get PBT group compositions
	SCOBI_deux_fast(adultData = trapData, windowData = window,
			 Run = paste0(r, "_HNC_sim"), RTYPE = "noclip_H", Hierarch_variables = c("GenParentHatchery", "Var1"),
	                  SizeCut = NULL, alph = 0.1, B = 0, writeBoot = F, pbtRates = tags,
			 adClipVariable = "AdClip", physTagsVariable = "PhysTag", pbtGroupVariable = "GenParentHatchery",
			 screenOutput = paste0(r, "_tempScreen.txt"), dataGroupVariable = "StrataVar")

	#run to get wild group compositions
	SCOBI_deux_fast(adultData = trapData, windowData = window,
			 Run = paste0(r, "_W_sim"), RTYPE = "wild", Hierarch_variables = c("GSI", "Var1"),
	                  SizeCut = NULL, alph = 0.1, B = 0, writeBoot = F, pbtRates = tags,
			 adClipVariable = "AdClip", physTagsVariable = "PhysTag", pbtGroupVariable = "GenParentHatchery",
			 screenOutput = paste0(r, "_tempScreen.txt"), dataGroupVariable = "StrataVar")

	#record results
	pbt_res <- read.table(paste0(r, "_HNC_sim_Estim_Grand_Totals_Hier_Var1.txt"), sep = "\t", header = TRUE, stringsAsFactors = FALSE)
	pbt_res$conCat <- paste0(pbt_res$GenParentHatchery, "_", pbt_res$Var1)
	tempGroups <- allGroups[allGroups %in% pbt_res$conCat]

	srSD_mean[1,tempGroups] <- pbt_res[match(tempGroups, pbt_res$conCat), "Estimated_total_for_run"]

	wild_res <- read.table(paste0(r, "_W_sim_Estim_Grand_Totals_Hier_Var1.txt"), sep = "\t", header = TRUE, stringsAsFactors = FALSE)
	wild_res$conCat <- paste0(wild_res$GSI, "_", wild_res$Var1)
	tempGroups <- allGroups[allGroups %in% wild_res$conCat]

	srSD_mean[1,tempGroups] <- wild_res[match(tempGroups, wild_res$conCat), "Estimated_total_for_run"]

	###############################
	#run SD - tag rate 100%
	###############################
	
	tags100 <- tags
	tags100[,2] <- 1
	
	#run to get PBT group compositions
	SCOBI_deux_fast(adultData = trapData, windowData = window,
			 Run = paste0(r, "_HNC_sim"), RTYPE = "noclip_H", Hierarch_variables = c("GenParentHatchery", "Var1"),
	                  SizeCut = NULL, alph = 0.1, B = 0, writeBoot = F, pbtRates = tags100,
			 adClipVariable = "AdClip", physTagsVariable = "PhysTag", pbtGroupVariable = "GenParentHatchery",
			 screenOutput = paste0(r, "_tempScreen.txt"), dataGroupVariable = "StrataVar")

	#run to get wild group compositions
	SCOBI_deux_fast(adultData = trapData, windowData = window,
			 Run = paste0(r, "_W_sim"), RTYPE = "wild", Hierarch_variables = c("GSI", "Var1"),
	                  SizeCut = NULL, alph = 0.1, B = 0, writeBoot = F, pbtRates = tags100,
			 adClipVariable = "AdClip", physTagsVariable = "PhysTag", pbtGroupVariable = "GenParentHatchery",
			 screenOutput = paste0(r, "_tempScreen.txt"), dataGroupVariable = "StrataVar")

	#record results
	
		pbt_res <- read.table(paste0(r, "_HNC_sim_Estim_Grand_Totals_Hier_Var1.txt"), sep = "\t", header = TRUE, stringsAsFactors = FALSE)
	pbt_res$conCat <- paste0(pbt_res$GenParentHatchery, "_", pbt_res$Var1)
	tempGroups <- allGroups[allGroups %in% pbt_res$conCat]

	srSD_tag100[1,tempGroups] <- pbt_res[match(tempGroups, pbt_res$conCat), "Estimated_total_for_run"]

	wild_res <- read.table(paste0(r, "_W_sim_Estim_Grand_Totals_Hier_Var1.txt"), sep = "\t", header = TRUE, stringsAsFactors = FALSE)
	wild_res$conCat <- paste0(wild_res$GSI, "_", wild_res$Var1)
	tempGroups <- allGroups[allGroups %in% wild_res$conCat]

	srSD_tag100[1,tempGroups] <- wild_res[match(tempGroups, wild_res$conCat), "Estimated_total_for_run"]
	

	###############################
	#run SD - spibetr FALSE
	###############################
	
	#only need to run wild as HNC is not affected
	#run to get wild group compositions
	SCOBI_deux_fast(adultData = trapData, windowData = window,
			 Run = paste0(r, "_W_sim"), RTYPE = "wild", Hierarch_variables = c("GSI", "Var1"),
	                  SizeCut = NULL, alph = 0.1, B = 0, writeBoot = F, pbtRates = tags,
			 adClipVariable = "AdClip", physTagsVariable = "PhysTag", pbtGroupVariable = "GenParentHatchery",
			 screenOutput = paste0(r, "_tempScreen.txt"), dataGroupVariable = "StrataVar", spibetr = FALSE)

	#record results

	wild_res <- read.table(paste0(r, "_W_sim_Estim_Grand_Totals_Hier_Var1.txt"), sep = "\t", header = TRUE, stringsAsFactors = FALSE)
	wild_res$conCat <- paste0(wild_res$GSI, "_", wild_res$Var1)
	tempGroups <- allGroups[allGroups %in% wild_res$conCat]

	srSD_spibetrFALSE[1,tempGroups] <- wild_res[match(tempGroups, wild_res$conCat), "Estimated_total_for_run"]
	
	###############################
	#run MLE
	###############################
	convergeBool <- FALSE
	resultBool <- tryCatch(
		{
				conv <- capture.output(
			mlePointEstimates <- MLEwrapper(trapData, tags = tags, GSIcol = "GSI", PBTcol = "GenParentHatchery", strataCol = "StrataVar", 
													  adFinCol = "AdClip", AI = TRUE, optimMethod = "L-BFGS-B", variableCols = "Var1", gr = params_grad_var, 
													  lower=10^-12, control = list(maxit=10000))
				)
				FALSE #return value to tryCatch
		}, error = function(e){
			print(e)
			#if problems encountered with optim, save data to go back and run manually 
			save(trapData, tags, file = paste0(sr, "_", r, "_error.rda"))
			return(TRUE)
		}
	)
	
	#if problems encountered with optim, mark position to go back and run manually
	if(isTRUE(resultBool)){
		srMLE_mean[1,] <- -9
		srMLE_lower[1,] <- -9
		srMLE_upper[1,] <- -9
		convergeBool <- NA
		
		return(list(
			srSD_mean[1,],
			srSD_lower[1,],
			srSD_upper[1,],
			srRec[1],
			srMLE_mean[1,],
			srMLE_lower[1,],
			srMLE_upper[1,],
			convergeBool,
			srSD_tag100[1,],
			srSD_spibetrFALSE[1,]
		))
	}

	if(length(conv) > 0) convergeBool <- TRUE

	strataComp <- list()
	tempGroups <- c()
	for(i in 1:length(mlePointEstimates)){
		tMat <- mlePointEstimates[[i]]$piTot * mlePointEstimates[[i]]$piVar * popSize[i,2]
		strataComp[[i]] <- c(tMat[,1], tMat[,2])
		names(strataComp[[i]]) <- c(paste0(rownames(tMat), "_", colnames(tMat)[1]), paste0(rownames(tMat), "_", colnames(tMat)[2]))
		
		tempGroups <- c(tempGroups, names(strataComp[[i]]))
	}
	#now sum up across strata
	tempGroups <- unique(tempGroups)
	for(g in tempGroups){
		tempSum <- 0
		for(strat in strataComp){
			# removign NA in case group does not exist in this strata
			tempSum <- sum(tempSum, strat[g], na.rm = TRUE)
		}
		srMLE_mean[1,g] <- tempSum
	}
	
	


	## utilizing the sr* data structures is a little lazy, but it works
	return(list(
		srSD_mean[1,],
		srSD_lower[1,],
		srSD_upper[1,],
		srRec[1],
		srMLE_mean[1,],
		srMLE_lower[1,],
		srMLE_upper[1,],
		convergeBool,
		srSD_tag100[1,],
		srSD_spibetrFALSE[1,]
		
	))
	
}



for(sr in sampRate){
	print(sr)
	# generate data in chunks of numSims for processing
	dataList <- list()
	for(r in 1:numSims){
		varMat <- matrix(0, nrow = nrow(pbtComp) + nrow(gsiComp), ncol = 2)
		#using beta distribution to generate new compositions for each simulation.
		# different between hatchery and wild
		varMat[,1] <- c(rbeta(nrow(pbtComp), 30, 70), rbeta(nrow(gsiComp), 70, 30))
		varMat[,2] <- 1 - varMat[,1]
		trueVarMat[[length(trueVarMat) + 1]] <- varMat # save for calculation of true value
		varMat <- list(
				cat2 = varMat
			)
		
		trapData <- data.frame()
		for(s in 1:nrow(popSize)){
			tempData <- generatePBTGSIdata(sampRate = sr, censusSize = popSize[s,2], relSizePBTgroups = pbtComp[,(s+1)], tagRates = tagRates[,2], 
											 obsTagRates = tagRates[,2], physTagRates = rep(0,nrow(tagRates)),
					    true_clipped = 0, true_noclip_H = (1 - propWild[s,2]), true_wild = propWild[s,2], relSizeGSIgroups = gsiComp[,(s+1)], 
					    PBT_GSI_calls = gsiOfPbt, varMatList = varMat)
			tempData[[1]]$StrataVar <- popSize[s,1]
			tempData[[1]]$GSI <- paste0("GSIgroup", tempData[[1]]$GSI)
			tempData[[1]]$Var1 <- paste0("cat", tempData[[1]]$Var1)
			trapData <- rbind(trapData, tempData[[1]])
		}
		#get tag rate in a nice format
		tags <- tempData[[2]]
		
		#save data
		dataList[[r]] <- list(trapData, tags, r, popSize) #saving r to use as prefix for SD output files
	}
	
	# #testing
	# print(compFunc(dataList[[1]]))
	
	#now run in parallel
	results <- mclapply(dataList, compFunc, mc.cores = countCores)
	
	#upack results and assign to sr* matrices
	for(i in 1:length(results)){
		tempRes <- results[[i]]
		
		srSD_mean[currentRow,] <- tempRes[[1]]
		srSD_lower[currentRow,] <- tempRes[[2]]
		srSD_upper[currentRow,] <- tempRes[[3]]
		srRec[currentRow] <- tempRes[[4]]
		srMLE_mean[currentRow,] <- tempRes[[5]]
		srMLE_lower[currentRow,] <- tempRes[[6]]
		srMLE_upper[currentRow,] <- tempRes[[7]]
		convergeMLE[currentRow] <- tempRes[[8]]
		srSD_tag100[currentRow,] <- tempRes[[9]]
		srSD_spibetrFALSE[currentRow,] <- tempRes[[10]]
				
		currentRow <- currentRow + 1
	}
	

	
}

#calculate true values
trueComp <- rep(0, ncol(srSD_mean))
names(trueComp) <- colnames(srSD_mean)
for(i in 2:ncol(gsiComp)){
	tot <- popSize[(i-1),2] * propWild[(i-1),2]
	tempnorm <- gsiComp[,i] / sum(gsiComp[,i])
	trueComp[gsiComp[,1]] <- trueComp[gsiComp[,1]] + (tempnorm * tot)
}
for(i in 2:ncol(pbtComp)){
	tot <- popSize[(i-1),2] * (1-propWild[(i-1),2])
	tempnorm <- pbtComp[,i] / sum(pbtComp[,i])
	tempNames <- gsub("PBTgroup", "pbtGroup", pbtComp$Group)
	trueComp[tempNames] <- trueComp[tempNames] + (tempnorm * tot)
}

#save estimates and true values
save(srSD_mean, srSD_upper, srSD_lower, srRec, trueComp, trueVarMat, convergeMLE, srMLE_mean,
	  srMLE_lower, srMLE_upper, srSD_tag100, srSD_spibetrFALSE, file = "./rdaOutputs/addBinomVarDiff.rda")
